# API Contract: Go Coordination Engine

This document defines the **two critical integration boundaries** for the Go Coordination Engine.

## 1. Upstream API (Consumed by MCP Server)

The Go engine exposes the same REST API as the current Python coordination engine so that the MCP server does not need code changes.

### Base URL
- `http://coordination-engine:8080/api/v1`

### Endpoints

#### `GET /health`
Health check endpoint.

**Response** (200 OK):
```json
{
  "status": "healthy",
  "timestamp": "2025-12-18T10:00:00Z",
  "version": "1.0.0",
  "dependencies": {
    "kubernetes": "ok",
    "ml_service": "ok",
    "argocd": "ok"
  }
}
```

#### `POST /remediation/trigger`
Trigger a remediation workflow.

**Request Body**:
```json
{
  "incident_id": "inc-12345",
  "namespace": "production",
  "resource": {
    "kind": "Deployment",
    "name": "payment-service"
  },
  "issue": {
    "type": "pod_crash_loop",
    "description": "Pods in CrashLoopBackOff",
    "severity": "high"
  }
}
```

**Response** (202 Accepted):
```json
{
  "workflow_id": "wf-67890",
  "status": "in_progress",
  "deployment_method": "argocd",
  "estimated_duration": "5m"
}
```

#### `GET /incidents`
List recent incidents and their remediation status.

**Query Parameters**:
- `namespace` (optional): Filter by namespace
- `severity` (optional): Filter by severity (low, medium, high, critical)
- `limit` (optional, default: 50): Max results

**Response** (200 OK):
```json
{
  "incidents": [
    {
      "id": "inc-12345",
      "namespace": "production",
      "resource": "Deployment/payment-service",
      "issue_type": "pod_crash_loop",
      "severity": "high",
      "created_at": "2025-12-18T09:45:00Z",
      "status": "remediated",
      "workflow_id": "wf-67890"
    }
  ],
  "total": 1
}
```

#### `GET /workflows/{id}`
Get workflow execution details.

**Response** (200 OK):
```json
{
  "id": "wf-67890",
  "incident_id": "inc-12345",
  "status": "completed",
  "deployment_method": "argocd",
  "layers": ["application"],
  "steps": [
    {
      "order": 0,
      "layer": "application",
      "description": "Trigger ArgoCD sync for payment-service",
      "status": "completed",
      "started_at": "2025-12-18T09:50:00Z",
      "completed_at": "2025-12-18T09:52:00Z"
    }
  ],
  "checkpoints": [
    {
      "layer": "application",
      "after_step": 0,
      "status": "passed",
      "checks": ["pods_running", "endpoints_healthy"]
    }
  ],
  "created_at": "2025-12-18T09:50:00Z",
  "completed_at": "2025-12-18T09:52:00Z"
}
```

#### `POST /recommendations`
Get ML-powered remediation recommendations with predictive analytics.

**Request Body** (all fields optional):
```json
{
  "timeframe": "6h",
  "include_predictions": true,
  "confidence_threshold": 0.7,
  "namespace": "production"
}
```

**Request Parameters**:
- `timeframe` (optional, default: "6h"): Prediction window - `"1h"`, `"6h"`, or `"24h"`
- `include_predictions` (optional, default: true): Include ML-powered predictions from KServe
- `confidence_threshold` (optional, default: 0.7): Minimum confidence score (0.0-1.0)
- `namespace` (optional): Filter recommendations by namespace

**Response** (200 OK):
```json
{
  "status": "success",
  "timestamp": "2026-01-11T17:00:00Z",
  "timeframe": "6h",
  "recommendations": [
    {
      "id": "rec-001",
      "type": "proactive",
      "issue_type": "memory_pressure",
      "target": "Deployment/payment-service",
      "namespace": "production",
      "severity": "high",
      "confidence": 0.85,
      "predicted_time": "2026-01-11T19:30:00Z",
      "recommended_actions": [
        "increase_memory_limit",
        "add_horizontal_scaling"
      ],
      "evidence": [
        "Memory usage trend: 65% → 85% over 2h",
        "Historical pattern: similar increase before OOM"
      ],
      "source": "ml_prediction",
      "related_incident_id": "inc-12345"
    }
  ],
  "total_recommendations": 1,
  "ml_enabled": true
}
```

**Recommendation Types**:
- `proactive`: Predicted issues that haven't occurred yet
- `reactive`: Recommendations based on current/recent issues

**Recommendation Sources**:
- `ml_prediction`: Generated by KServe predictive-analytics model
- `historical_analysis`: Based on historical incident patterns
- `pattern_detection`: Based on detected failure patterns

**Error Response** (400 Bad Request):
```json
{
  "status": "error",
  "error": "Invalid timeframe: must be '1h', '6h', or '24h'"
}
```

For details, see:
- MCP ADR-006: Integration Architecture
- MCP ADR-014: Go Coordination Engine Integration (to be created)

## 2. Downstream ML Integration

The Go coordination engine supports two ML integration modes:

### 2.1 KServe Integration (Recommended - ADR-039)

The coordination engine calls KServe InferenceServices directly for ML predictions.
This is the recommended approach for both vanilla Kubernetes and OpenShift deployments.

**Configuration**:
```yaml
env:
  - name: ENABLE_KSERVE_INTEGRATION
    value: "true"
  - name: KSERVE_NAMESPACE
    value: "self-healing-platform"
  - name: KSERVE_ANOMALY_DETECTOR_SERVICE
    value: "anomaly-detector-predictor"
  - name: KSERVE_PREDICTIVE_ANALYTICS_SERVICE
    value: "predictive-analytics-predictor"
```

**KServe Service DNS**:
```
http://<service-name>.<namespace>.svc.cluster.local/v1/models/<model>:predict
```

#### KServe v1 Prediction API

**Required Endpoints**:
- `GET /v1/models/<model>` - Model metadata
- `POST /v1/models/<model>:predict` - Inference
- `GET /v1/models` - List available models

#### `POST /v1/models/anomaly-detector:predict`
Detect anomalies using KServe InferenceService.

**Request Body** (KServe v1 format):
```json
{
  "instances": [
    [0.5, 1.2, 0.8],
    [0.3, 0.9, 1.1]
  ]
}
```

**Response** (200 OK):
```json
{
  "predictions": [-1, 1],
  "model_name": "anomaly-detector",
  "model_version": "v2"
}
```

**Prediction Values**:
- `-1` = Anomaly detected
- `1` = Normal (no anomaly)

#### `POST /v1/models/predictive-analytics:predict`
Predict future issues using KServe InferenceService.

**Request Body**:
```json
{
  "instances": [
    [0.75, 0.80, 0.02],
    [0.85, 0.90, 0.05]
  ]
}
```

**Response** (200 OK):
```json
{
  "predictions": [-1, -1],
  "model_name": "predictive-analytics",
  "model_version": "v1"
}
```

#### `GET /v1/models/anomaly-detector`
Get model metadata.

**Response** (200 OK):
```json
{
  "name": "anomaly-detector",
  "versions": ["v1", "v2"],
  "platform": "sklearn"
}
```

### Go KServe Client Implementation

```go
// internal/integrations/kserve_client.go
package integrations

import (
    "bytes"
    "context"
    "encoding/json"
    "fmt"
    "net/http"
    "time"
)

type KServeClient struct {
    anomalyDetectorURL     string
    predictiveAnalyticsURL string
    httpClient             *http.Client
}

type KServeV1Request struct {
    Instances [][]float64 `json:"instances"`
}

type KServeV1Response struct {
    Predictions  []int  `json:"predictions"`
    ModelName    string `json:"model_name,omitempty"`
    ModelVersion string `json:"model_version,omitempty"`
}

// DetectAnomalies calls KServe anomaly detector
func (c *KServeClient) DetectAnomalies(
    ctx context.Context,
    instances [][]float64,
) (*AnomalyDetectionResult, error) {
    endpoint := fmt.Sprintf("%s/v1/models/anomaly-detector:predict", 
        c.anomalyDetectorURL)
    
    req := &KServeV1Request{Instances: instances}
    // ... implementation
}
```

### 2.2 Legacy ML Service (Deprecated)

The legacy Python ML service integration is deprecated but still supported for backward compatibility.

**Configuration**:
```yaml
env:
  - name: ENABLE_KSERVE_INTEGRATION
    value: "false"
  - name: ML_SERVICE_URL
    value: "http://aiops-ml-service:8080"
```

#### `POST /api/v1/anomaly/detect`
Detect anomalies in metrics data.

**Request Body**:
```json
{
  "metrics": [
    {
      "timestamp": "2025-12-18T10:00:00Z",
      "metric_name": "pod_cpu_usage",
      "value": 0.85,
      "labels": {
        "namespace": "production",
        "pod": "payment-service-abc123"
      }
    }
  ],
  "model": "isolation_forest",
  "threshold": 0.7
}
```

**Response** (200 OK):
```json
{
  "anomalies": [
    {
      "timestamp": "2025-12-18T10:00:00Z",
      "metric_name": "pod_cpu_usage",
      "score": 0.92,
      "is_anomaly": true,
      "severity": "high"
    }
  ],
  "overall_score": 0.92,
  "confidence": 0.88
}
```

#### `POST /api/v1/prediction/predict`
Predict future issues based on current state.

**Request Body**:
```json
{
  "namespace": "production",
  "resource": "Deployment/payment-service",
  "current_state": {
    "replicas": 3,
    "cpu_usage": 0.75,
    "memory_usage": 0.80,
    "error_rate": 0.02
  },
  "prediction_horizon": "1h"
}
```

**Response** (200 OK):
```json
{
  "predictions": [
    {
      "issue_type": "memory_pressure",
      "probability": 0.85,
      "expected_time": "45m",
      "severity": "high",
      "recommended_actions": [
        "increase_memory_limit",
        "add_horizontal_scaling"
      ]
    }
  ],
  "confidence": 0.82
}
```

#### `POST /api/v1/pattern/analyze`
Analyze patterns in historical data.

**Request Body**:
```json
{
  "namespace": "production",
  "time_range": {
    "start": "2025-12-18T00:00:00Z",
    "end": "2025-12-18T10:00:00Z"
  },
  "resource_types": ["Deployment", "StatefulSet"]
}
```

**Response** (200 OK):
```json
{
  "patterns": [
    {
      "pattern_type": "recurring_crash",
      "frequency": "every 2h",
      "affected_resources": ["Deployment/payment-service"],
      "confidence": 0.88,
      "root_cause_hints": ["memory_leak", "connection_timeout"]
    }
  ]
}
```

## Compatibility Guarantees

- MCP server continues to work unchanged
- KServe integration is the recommended approach (ADR-039)
- Legacy ML_SERVICE_URL is deprecated but still supported
- Only the orchestration implementation changes (Python → Go)

## References

- [KServe v1 Protocol](https://kserve.github.io/website/latest/modelserving/data_plane/v1_protocol/)
- [ADR-039: User-Deployed KServe Models](../docs/adrs/039-user-deployed-kserve-models.md)


